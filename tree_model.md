
### gbdt和xgboost区别

    1.GBDT是机器学习算法，而XGBoost是算法的工程实现
    2.使用CART作为基分类器时，XGBoost显式的加入了正则项来控制模型的复杂度，防止过拟合，提高了模型的泛化能力
    3.GBDT只使用了代价函数的一阶导数信息，而XGBoost对代价函数进行二阶泰勒展开，同时使用一阶和二阶信息
    4.传统的GBDT采用CART作为基分类器，而XGBoost支持多种类型的基分类器
    5.传统的GBDT迭代时采用全部的数据，而XGBoost采用了随机森林相似的策略，支持对数据进行 采样
    6.传统的GBDT没有对缺失值的处理策略，而XGBoost自动学习出对缺失值的处理策略


### xgboost

    核心思想：
    1.xgboost是属于boosting家族，是GBDT算法的一个工程实现
    2.在模型的训练过程中是拟合残差，在目标函数中使用了二阶泰勒展开并加入了正则
    3.在决策树的生成过程中采用了精确贪心的思路，寻找最佳分裂点的时候，使用了预排序算法 对所有特征都按照特征的数值进行预排序， 然后遍历所有特征上的所有分裂点位，计算按照这些候选分裂点分裂后的全部样本的目标函数增益，找到最大的那个增益对应的特征和候选分裂点位，从而进行分裂。这样一层一层的完成建树过程
    4.xgboost训练的时候，是通过加法的方式进行训练，也就是每一颗树通过拟合与真值的残差再训练一棵树出来，最后的预测结果是所有树的加和表示

    优点：
    1.高效可扩展。考虑了当数据量比较大，内存不够时怎么有效的使用磁盘，主要是结合多线程、数据压缩、分片的方法，尽可能的提高算法的效率
    2.鲁棒性强。相对于深度学习模型不需要精细调参便能取得接近的效果
    3.自动处理缺失值。当训练样本存在缺失值时，能自动学习分裂方向。如果训练无缺失值，而预测有缺失的话默认分到左子树
    4.防止过拟合。代价函数引入正则化项，控制了模型的复杂度，正则化项包含全部叶子节点的个数，每个叶子节点输出的score的L2模的平方和。降低了模型的方差，防止模型过拟合
    5.支持特征粒度并行。但并不是tree粒度上的，决策树最耗时的步骤是对特征的值排序，xgBoosting在迭代之前，先进行预排序，存为block结构，每次迭代，重复使用该结构，降低了模型的计算；block结构也为模型提供了并行可能，在进行结点的分裂时，计算每个特征的增益，选增益最大的特征进行下一步分裂，那么各个特征的增益可以开多线程进行
    6.支持列抽样。不仅能降低过拟合，还能减少计算​​​​​​​
    7.shrinkage（缩减），相当于学习速率（XGBoost中的eta）。XGBoost在进行完一次迭代时，会将叶子节点的权值乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间
    8.树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以XGBoost还提出了一种可并行的近似算法，用于高效地生成候选的分割点。近似算法首先根据特征分布的分位数提出了候选划分点，然后将连续型特征映射到由这些候选点划分的桶中(分桶)，然后聚合统计信息找到所有区间的最佳分裂点

    缺点：
    1.对cache优化不友好。在预排序后，特征对梯度的访问是一种随机访问，并且不同的特征访问的顺序不一样，无法对cache进行优化。同时，在每一层长树的时候，需要随机访问一个行索引到叶子索引的数组，并且不同特征访问的顺序也不一样，也会造成较大的cache miss，降低算法效率
    2.虽然利用特征预排序和增益近似求解算法可以降低寻找最佳分裂点的计算量，但在节点分裂过程中仍需要遍历数据集，空间消耗大。这样的算法需要保存数据的特征值，还保存了特征排序的结果（例如排序后的索引，为了后续快速的计算分割点），这里需要消耗训练数据两倍的内存。 
    3.只适合处理结构化数据。相对于深度学习算法来说，XGBoost只适合处理结构化的特征数据，而对于类似图像中的目标检测等任务重的非结构化数据没有很好的处理能力
    4.不适合处理超高维特征数据。对于中低维数据具有很好的处理速度和精度，但是对于例如大规模图像物体识别，或者是推荐算法的某些场景中会出现的超高维特征的数据就无能为力了，这时候我们就需要借助于深度学习等算法

### lightGBM
    优化：
    1.基于 Histogram 的决策树算法
    2.带深度限制的 Leaf-wise 的叶子生长策略
    3.直方图做差加速
    4.直接支持类别特征(Categorical Feature)
    4.Cache 命中率优化
    5.基于直方图的稀疏特征优化